# Robotic Integration
[Link of the project repository](https://github.com/pierredaudin/Robotic-Integration/tree/master)

This integration project aims to familiarize with the ROS environment applied to industrial robotics.

To achieve this, we will work both independently and as a full group on a project involving the creation of a trajectory for a Yaskawa HC10 robotic arm to scan an object using a 3D sensor.

This project should be carried out as a feasibility study. Each step must be documented to allow the client to replicate the results we obtained.

The steps to be completed are as follows:

1. Familiarize yourself with the ROS environment and the MoveIt! trajectory generation tool.
2. Use the MoveIt! API to generate trajectories in Cartesian space.
3. Integrate a simulation environment (Gazebo) and add a 3D-type sensor.
4. Integrate the 3D sensor data into the trajectory generation program.

The work will be done on the provided virtual machine with the following specifications:
- Ubuntu 20.04
- ROS Noetic + MoveIt, ROS Control packages, etc.
- Visual Studio Code
- Python 3

The work will be carried out by a full minor group (around ten students).
Each group must submit:
- A document presenting the work done and the results obtained.
- The results will be presented during an oral presentation at the time of the report submission.

The evaluation grade will take into account:
* Attendance at sessions (10%)
* Quality of the final presentation (20%)
* Quality of the final report (20%)
* The grade of the MCQ (50%) which will take place during the last session, after the presentation.

**Getting Started with the Environment**

From Oracle VM Virtual Box, import the file C:\virtual_b\3ASRI-ProjetIntergation.ova

From the provided virtual machine:
- Create a catkin workspace:
  ```bash
  mkdir -p catkin_ws/src
  cd catkin_ws
  . /opt/ros/noetic/setup.bash
  ```

- Clone the repository containing the HC10 robot model:
  ```bash
  cd src
  git clone https://github.com/ros-industrial/motoman.git
  cd ..
  catkin build
  . devel/setup.bash
  ```

- Update the HC10 model (hc10_macro.xacro):
  - Add an additional 'link' at the beginning of the file:
    ```xml
    <link name="world"/>
    ```

  - Add inertia values for each link:
    ```xml
    <inertial>
       <origin xyz="0 0 0" rpy="0 0 0"/>
       <mass value="0.1"/>
       <inertia ixx="0.03" ixy="0.03" ixz="0.03" iyy="0.0" iyz="0.0" izz="0.0"/>
    </inertial>
    ```

  - Add a joint between the 'world' link and the robot base:
    ```xml
    <joint name="world_fixed" type="fixed">
       <parent link="world"/>
       <child link="${prefix}base_link"/>
    </joint>
    ```

  - Add damping factors to each 'revolute' joint:
    ```xml
    <dynamics damping="1"/>
    ```

- Create the hc10_moveit_config package based on the following tutorial, and then test the generated package:

  https://moveit.github.io/moveit_tutorials/doc/setup_assistant/setup_assistant_tutorial.html

**Trajectory Generation**

Based on the available documentation regarding the MoveGroup Python interface:

- Write a Python script that uses MoveIt to generate a Cartesian trajectory.
- Update the hc10_moveit_config package if necessary.
- Reference: https://moveit.github.io/moveit_tutorials/doc/move_group_python_interface/move_group_python_interface_tutorial.html

**Simulation Environment**

Integrate the necessary properties to use Gazebo as a simulator:

- Update the xacro file to include the components required for Gazebo, using the following tutorial (https://moveit.github.io/moveit_tutorials/doc/gazebo_simulation/gazebo_simulation.html) and the URDF generated by MoveIt!
- Use the demo_gazebo.launch script to test your configuration.

**Sensor Integration**

To integrate a 3D sensor like Kinect into our environment, you need to:

- Add the sensor model and position it relative to the robot. Refer to the information provided here: https://moveit.github.io/moveit_tutorials/doc/mesh_filter/mesh_filter_tutorial.html
- Implement the ROS perception pipeline to simulate sensor data in Gazebo so that it can be utilized by MoveIt!. Use the example provided here: https://moveit.github.io/moveit_tutorials/doc/perception_pipeline/perception_pipeline_tutorial.html
